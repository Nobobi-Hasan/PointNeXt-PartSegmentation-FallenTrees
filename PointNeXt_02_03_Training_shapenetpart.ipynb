{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nobobi-Hasan/PointNeXt-PartSegmentation-FallenTrees/blob/main/PointNeXt_02_03_Training_shapenetpart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "YAhNWDtNOK3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yhFy7Up_OC2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9f1894-7333-4284-b112-323e28632e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the project root in Drive\n",
        "DRIVE_PROJECT_ROOT = \"/content/drive/MyDrive/ML_Projects/PointNeXt\"\n",
        "\n",
        "# Subfolders\n",
        "DRIVE_DATA_DIR = os.path.join(DRIVE_PROJECT_ROOT, \"Data\")\n",
        "DRIVE_MODELS_DIR = os.path.join(DRIVE_PROJECT_ROOT, \"Models\")\n",
        "\n",
        "# Input paths\n",
        "DRIVE_ZIP_PATH = os.path.join(DRIVE_DATA_DIR, \"processed_data.zip\")\n",
        "LOCAL_DATA_DIR = \"/content/processed_data\"\n",
        "\n",
        "print(f\"Project Root: {DRIVE_PROJECT_ROOT}\")"
      ],
      "metadata": {
        "id": "m16azjY-OFhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606cf107-d81a-406d-9da3-ea7f90eae82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Root: /content/drive/MyDrive/ML_Projects/PointNeXt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEOzQvBtN1sV"
      },
      "outputs": [],
      "source": [
        "# Copy processed data from Drive\n",
        "if not os.path.exists(\"/content/processed_data\"):\n",
        "    if os.path.exists(DRIVE_ZIP_PATH):\n",
        "        print(\"Copying processed_data.zip from Drive...\")\n",
        "        shutil.copy(DRIVE_ZIP_PATH, \"/content/processed_data.zip\")\n",
        "        print(\"Unzipping...\")\n",
        "        !unzip -q -o /content/processed_data.zip -d /\n",
        "        print(\"Data Ready at /content/processed_data\")\n",
        "    else:\n",
        "        print(f\"Error: Could not find processed_data.zip at {DRIVE_ZIP_PATH}\")\n",
        "\n",
        "# Clone PointNeXt\n",
        "if not os.path.exists(\"/content/PointNeXt\"):\n",
        "    print(\"Cloning PointNeXt...\")\n",
        "    %cd /content\n",
        "    !git clone https://github.com/guochengqian/PointNeXt.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For openpoints"
      ],
      "metadata": {
        "id": "uWxJD5qWrUgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For openpoints\n",
        "\n",
        "%cd /content/PointNeXt\n",
        "\n",
        "# 1. Replace SSH url with HTTPS url in .gitmodules\n",
        "!sed -i 's/git@github.com:/https:\\/\\/github.com\\//' .gitmodules\n",
        "\n",
        "# 2. Sync the new URL\n",
        "!git submodule sync\n",
        "\n",
        "# 3. Update the submodule (This will work now)\n",
        "print(\"Downloading openpoints via HTTPS...\")\n",
        "!git submodule update --init --recursive\n",
        "\n",
        "print(\"\\u2705 Submodule 'openpoints' downloaded successfully.\")"
      ],
      "metadata": {
        "id": "xvcHjNHdVR_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88525412-0dc5-4087-b494-3ee6b5c7dec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PointNeXt\n",
            "Synchronizing submodule url for 'openpoints'\n",
            "Downloading openpoints via HTTPS...\n",
            "âœ… Submodule 'openpoints' downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config File"
      ],
      "metadata": {
        "id": "1QKZI0MtrZch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"/content/PointNeXt/cfgs/shapenetpart/custom_fallen_trees.yaml\"\n",
        "\n",
        "config_content = \"\"\"\n",
        "num_classes: 4\n",
        "shape_classes: 2\n",
        "epochs: 100\n",
        "\n",
        "# --- DATA CONFIG ---\n",
        "# Crucial Fix: Explicitly define feature keys to match your data loader\n",
        "feature_keys: 'pos,x'  # <--- THIS FIXES THE KEYERROR\n",
        "\n",
        "model:\n",
        "  NAME: BasePartSeg\n",
        "  encoder_args:\n",
        "    NAME: PointNextEncoder\n",
        "    blocks: [1, 1, 1, 1, 1]\n",
        "    strides: [1, 2, 2, 2, 2]\n",
        "    width: 32\n",
        "    in_channels: 7\n",
        "    sa_layers: 3\n",
        "    sa_use_res: True\n",
        "    radius: 0.1\n",
        "    radius_scaling: 2.5\n",
        "    nsample: 32\n",
        "    expansion: 4\n",
        "    aggr_args:\n",
        "      feature_type: 'dp_fj'\n",
        "    reduction: 'max'\n",
        "    group_args:\n",
        "      NAME: 'ballquery'\n",
        "      normalize_dp: True\n",
        "    conv_args:\n",
        "      order: conv-norm-act\n",
        "    act_args:\n",
        "      act: 'relu'\n",
        "    norm_args:\n",
        "      norm: 'bn'\n",
        "  decoder_args:\n",
        "    NAME: PointNextPartDecoder\n",
        "    cls_map: curvenet\n",
        "  cls_args:\n",
        "    NAME: SegHead\n",
        "    global_feat: max,avg\n",
        "    num_classes: 4\n",
        "    shape_classes: 2\n",
        "    in_channels: null\n",
        "    norm_args:\n",
        "      norm: 'bn'\n",
        "\n",
        "dataset:\n",
        "  common:\n",
        "    NAME: FallenTreePart\n",
        "    data_root: /content/processed_data\n",
        "    use_normal: False\n",
        "    use_xyz: True\n",
        "    num_points: 2048\n",
        "  train:\n",
        "    split: train\n",
        "  val:\n",
        "    split: val\n",
        "\n",
        "batch_size: 16\n",
        "dataloader:\n",
        "  num_workers: 4\n",
        "optimizer:\n",
        "  NAME: adamw\n",
        "  weight_decay: 1.0e-4\n",
        "criterion_args:\n",
        "  NAME: Poly1FocalLoss\n",
        "\n",
        "sched:\n",
        "  # NAME: CosineAnnealingLR\n",
        "  # T_max: 100\n",
        "  # min_lr: 1.0e-5\n",
        "  # warmup_epochs: 0\n",
        "  NAME: MultiStepLR\n",
        "  milestones: [70, 90]  # Drop LR at epoch 70 and 90\n",
        "  gamma: 0.1\n",
        "  warmup_epochs: 0\n",
        "\n",
        "datatransforms:\n",
        "  train: [PointsToTensor, PointCloudScaling, PointCloudCenterAndNormalize, PointCloudJitter, ChromaticDropGPU]\n",
        "  val: [PointsToTensor, PointCloudCenterAndNormalize]\n",
        "  kwargs:\n",
        "    jitter_sigma: 0.001\n",
        "    jitter_clip: 0.005\n",
        "    scale: [0.8, 1.2]\n",
        "    gravity_dim: 1\n",
        "    angle: [0, 1.0, 0]\n",
        "\n",
        "log_dir: /content/PointNeXt/log/shapenetpart/custom_trees\n",
        "\"\"\"\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    f.write(config_content)\n",
        "print(f\"\\u2705 Config Updated: Removed 'heights' from feature_keys.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2bUEH8j4F8I",
        "outputId": "b95304a8-763b-4b44-9fb7-4262b86eec5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Config Updated: Removed 'heights' from feature_keys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Handle"
      ],
      "metadata": {
        "id": "B_HEgPDlrdMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the directory\n",
        "new_dataset_dir = \"/content/PointNeXt/openpoints/dataset/fallentree\"\n",
        "os.makedirs(new_dataset_dir, exist_ok=True)\n",
        "print(f\"\\U0001F4BE Created folder: {new_dataset_dir}\")\n",
        "\n",
        "# Create the '__init__.py' to make it a package\n",
        "init_path = os.path.join(new_dataset_dir, \"__init__.py\")\n",
        "with open(init_path, 'w') as f:\n",
        "    f.write(\"from .fallentree import FallenTreePart\\n\")\n",
        "print(f\"\\u2705 Created: {init_path}\")\n",
        "\n",
        "# Create the 'fallentree.py' (The Custom Loader)\n",
        "code_path = os.path.join(new_dataset_dir, \"fallentree.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYNH_fgPgvC8",
        "outputId": "3c2c4877-48da-4324-c2c4-5539e1d8b4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ Created folder: /content/PointNeXt/openpoints/dataset/fallentree\n",
            "âœ… Created: /content/PointNeXt/openpoints/dataset/fallentree/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Path\n",
        "code_path = \"/content/PointNeXt/openpoints/dataset/fallentree/fallentree.py\"\n",
        "\n",
        "# Define Code\n",
        "dataset_code = \"\"\"\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from ..build import DATASETS\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class FallenTreePart(Dataset):\n",
        "    classes = ['standing', 'fallen']\n",
        "    num_classes = 4\n",
        "    shape_classes = 2\n",
        "\n",
        "    # --- FIX: Add dummy key -1 for part_seg_refinement compatibility ---\n",
        "    # -1 points to all parts (0,1,2,3) so the code can find the max index\n",
        "    cls2parts = {\n",
        "        0: [0],\n",
        "        1: [1, 2, 3],\n",
        "        -1: [0, 1, 2, 3]\n",
        "    }\n",
        "\n",
        "    part_start = [0, 1]\n",
        "\n",
        "    # Pre-compute embedding\n",
        "    cls2partembed = torch.zeros(shape_classes, num_classes)\n",
        "    for i in [0, 1]: # Iterate only real classes\n",
        "        idx = cls2parts[i]\n",
        "        cls2partembed[i].scatter_(0, torch.LongTensor(idx), 1)\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_root,\n",
        "                 split=None,\n",
        "                 num_points=2048,\n",
        "                 use_normal=False,\n",
        "                 use_xyz=True,\n",
        "                 **kwargs):\n",
        "        self.root = data_root\n",
        "        self.npoints = num_points\n",
        "        self.split = split\n",
        "\n",
        "        # if split == 'val': split_name = 'test'\n",
        "        # else: split_name = split\n",
        "\n",
        "        split_name = split\n",
        "\n",
        "        split_file = os.path.join(self.root, 'train_test_split', f'shuffled_{split_name}_file_list.json')\n",
        "        if not os.path.exists(split_file):\n",
        "             raise FileNotFoundError(f\"Split list not found: {split_file}\")\n",
        "\n",
        "        logging.info(f\"Loading {split} split from: {split_file}\")\n",
        "        with open(split_file, 'r') as f:\n",
        "            raw_list = json.load(f)\n",
        "\n",
        "        self.file_list = []\n",
        "        for item in raw_list:\n",
        "            clean_item = item.replace(\\\"\\\\\\\\\\\", \\\"/\\\")\n",
        "            fname = os.path.basename(clean_item)\n",
        "            candidates = [\n",
        "                clean_item,\n",
        "                os.path.join(self.root, clean_item),\n",
        "                os.path.join(self.root, '0', fname),\n",
        "                os.path.join(self.root, '1', fname)\n",
        "            ]\n",
        "            found = False\n",
        "            for path in candidates:\n",
        "                if os.path.exists(path):\n",
        "                    self.file_list.append(path)\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "        logging.info(f\"Found {len(self.file_list)} valid files for {split} split.\")\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file_path = self.file_list[index]\n",
        "        cls_idx = 0 if '/0/' in file_path.replace('\\\\\\\\', '/') else 1\n",
        "\n",
        "        data = np.load(file_path).astype(np.float32)\n",
        "        xyz = data[:, 0:3]\n",
        "        features = data[:, 3:7]\n",
        "        part_label = data[:, 7].astype(np.int64)\n",
        "        cls_label = np.array([cls_idx]).astype(np.int64)\n",
        "\n",
        "        if len(xyz) >= self.npoints:\n",
        "            choice = np.random.choice(len(xyz), self.npoints, replace=False)\n",
        "        else:\n",
        "            choice = np.random.choice(len(xyz), self.npoints, replace=True)\n",
        "\n",
        "        xyz = xyz[choice]\n",
        "        features = features[choice]\n",
        "        part_label = part_label[choice]\n",
        "\n",
        "        return {'pos': xyz, 'x': features, 'y': part_label, 'cls': cls_label}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\"\"\"\n",
        "\n",
        "with open(code_path, 'w') as f:\n",
        "    f.write(dataset_code)\n",
        "print(f\"\\u2705 Updated: {code_path} with dummy key.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o_C0iiSgg7N",
        "outputId": "1ccbe726-30f7-4617-daa0-4b71330f9e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Updated: /content/PointNeXt/openpoints/dataset/fallentree/fallentree.py with dummy key.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the new folder in the Main Library\n",
        "# We need to add \"from .fallentree import FallenTreePart\" to openpoints/dataset/__init__.py\n",
        "\n",
        "main_init = \"/content/PointNeXt/openpoints/dataset/__init__.py\"\n",
        "with open(main_init, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "if \"fallentree\" not in content:\n",
        "    print(\"Registering new dataset in main __init__.py...\")\n",
        "    with open(main_init, 'a') as f:\n",
        "        f.write(\"\\nfrom .fallentree import FallenTreePart\\n\")\n",
        "    print(\"\\u2705 Registration Complete.\")\n",
        "else:\n",
        "    print(\"\\u2705 Already registered.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md659eXhgnNb",
        "outputId": "0f5283d7-d4ad-4fd3-e50f-1544cc104c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Already registered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "XmqBEuRjriVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "print(\"Installing Dependencies...\")\n",
        "%cd /content/PointNeXt\n",
        "\n",
        "# A. Install PyTorch 2.4.0 (Compatible)\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# B. Install torch-scatter/sparse\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "\n",
        "# C. Fix requirements.txt\n",
        "!sed -i 's/==.*//g' requirements.txt\n",
        "\n",
        "# D. Install requirements\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# E. SKIP 'pip install -e .' (Because setup.py is missing)\n",
        "print(\"\\u2705 Dependencies Installed. (Skipped setup.py)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPA2HJBBq0ep",
        "outputId": "f6faa676-d3db-4ac7-d3a3-9296ea7995a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Dependencies...\n",
            "/content/PointNeXt\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.12/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision==0.19.0 in /usr/local/lib/python3.12/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio==2.4.0 in /usr/local/lib/python3.12/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "Collecting torch-sparse\n",
            "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_sparse-0.6.18%2Bpt24cu121-cp312-cp312-linux_x86_64.whl (5.1 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-scatter, torch-sparse\n",
            "Successfully installed torch-scatter-2.1.2+pt24cu121 torch-sparse-0.6.18+pt24cu121\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.7.5)\n",
            "Collecting ninja (from -r requirements.txt (line 3))\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (5.2.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.13)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.19.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\n",
            "Collecting multimethod (from -r requirements.txt (line 11))\n",
            "  Downloading multimethod-2.0.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (3.15.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (3.10.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.23.0)\n",
            "Collecting pyvista (from -r requirements.txt (line 15))\n",
            "  Downloading pyvista-0.46.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (75.2.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (3.0.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (2.2.2)\n",
            "Collecting deepspeed (from -r requirements.txt (line 19))\n",
            "  Downloading deepspeed-0.18.2.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting shortuuid (from -r requirements.txt (line 20))\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/c0/44/21d6bf170bf40b41396480d8d49ad640bca3f2b02139cd52aa1e272830a5/shortuuid-1.0.13-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting mkdocs-material (from -r requirements.txt (line 23))\n",
            "  Downloading mkdocs_material-9.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting mkdocs-awesome-pages-plugin (from -r requirements.txt (line 24))\n",
            "  Downloading mkdocs_awesome_pages_plugin-2.10.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting mdx_truly_sane_lists (from -r requirements.txt (line 25))\n",
            "  Downloading mdx_truly_sane_lists-1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 4)) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 14)) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 14)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 14)) (4.5.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 14)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 14)) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 14)) (4.15.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.12/dist-packages (from pyvista->-r requirements.txt (line 15)) (1.8.2)\n",
            "Requirement already satisfied: scooby>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from pyvista->-r requirements.txt (line 15)) (0.11.0)\n",
            "Collecting vtk!=9.4.0 (from pyvista->-r requirements.txt (line 15))\n",
            "  Downloading vtk-9.5.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 18)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 18)) (2025.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed->-r requirements.txt (line 19)) (0.8.1)\n",
            "Collecting hjson (from deepspeed->-r requirements.txt (line 19))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed->-r requirements.txt (line 19)) (1.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from deepspeed->-r requirements.txt (line 19)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed->-r requirements.txt (line 19)) (9.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from deepspeed->-r requirements.txt (line 19)) (2.4.0+cu121)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from deepspeed->-r requirements.txt (line 19)) (13.580.82)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from mkdocs-material->-r requirements.txt (line 23)) (2.17.0)\n",
            "Collecting backrefs>=5.7.post1 (from mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading backrefs-6.1-py312-none-any.whl.metadata (3.0 kB)\n",
            "Collecting colorama>=0.4 (from mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jinja2>=3.1 in /usr/local/lib/python3.12/dist-packages (from mkdocs-material->-r requirements.txt (line 23)) (3.1.6)\n",
            "Collecting mkdocs-material-extensions>=1.3 (from mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting mkdocs>=1.6 (from mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading mkdocs-1.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting paginate>=0.5 (from mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading paginate-0.5.7-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pygments>=2.16 in /usr/local/lib/python3.12/dist-packages (from mkdocs-material->-r requirements.txt (line 23)) (2.19.2)\n",
            "Collecting pymdown-extensions>=10.2 (from mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading pymdown_extensions-10.17.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: natsort>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from mkdocs-awesome-pages-plugin->-r requirements.txt (line 24)) (8.4.0)\n",
            "Collecting wcmatch>=7 (from mkdocs-awesome-pages-plugin->-r requirements.txt (line 24))\n",
            "  Downloading wcmatch-10.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 14)) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1->mkdocs-material->-r requirements.txt (line 23)) (3.0.3)\n",
            "Collecting ghp-import>=1.0 (from mkdocs>=1.6->mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading ghp_import-2.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting mergedeep>=1.3.4 (from mkdocs>=1.6->mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mkdocs-get-deps>=0.2.0 (from mkdocs>=1.6->mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading mkdocs_get_deps-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pathspec>=0.11.1 (from mkdocs>=1.6->mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyyaml-env-tag>=0.1 (from mkdocs>=1.6->mkdocs-material->-r requirements.txt (line 23))\n",
            "  Downloading pyyaml_env_tag-1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: watchdog>=2.0 in /usr/local/lib/python3.12/dist-packages (from mkdocs>=1.6->mkdocs-material->-r requirements.txt (line 23)) (6.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 14)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 14)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 4)) (2025.11.12)\n",
            "Collecting bracex>=2.1.1 (from wcmatch>=7->mkdocs-awesome-pages-plugin->-r requirements.txt (line 24))\n",
            "  Downloading bracex-2.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 4)) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 4)) (1.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (3.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed->-r requirements.txt (line 19)) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed->-r requirements.txt (line 19)) (12.6.85)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 14)) (5.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->deepspeed->-r requirements.txt (line 19)) (1.3.0)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multimethod-2.0.2-py3-none-any.whl (9.6 kB)\n",
            "Downloading pyvista-0.46.4-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading mkdocs_material-9.7.0-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mkdocs_awesome_pages_plugin-2.10.1-py3-none-any.whl (15 kB)\n",
            "Downloading mdx_truly_sane_lists-1.3-py3-none-any.whl (6.1 kB)\n",
            "Downloading backrefs-6.1-py312-none-any.whl (398 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m398.8/398.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading mkdocs-1.6.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mkdocs_material_extensions-1.3.1-py3-none-any.whl (8.7 kB)\n",
            "Downloading paginate-0.5.7-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pymdown_extensions-10.17.2-py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m266.6/266.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vtk-9.5.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (112.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.3/112.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wcmatch-10.1-py3-none-any.whl (39 kB)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bracex-2.6-py3-none-any.whl (11 kB)\n",
            "Downloading ghp_import-2.1.0-py3-none-any.whl (11 kB)\n",
            "Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading mkdocs_get_deps-0.2.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pyyaml_env_tag-1.1-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.18.2-py3-none-any.whl size=1763305 sha256=437dc53f53620b36def4798bff5c8b211b5cb4b910ac0c4acaa21891a1f503ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/ad/2e/e03d4739ddc0417efd8a120c2b9e784005aa226037e558c163\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: paginate, hjson, shortuuid, pyyaml-env-tag, pymdown-extensions, pathspec, ninja, multimethod, mkdocs-material-extensions, mergedeep, mdx_truly_sane_lists, colorama, bracex, backrefs, wcmatch, mkdocs-get-deps, ghp-import, vtk, mkdocs, pyvista, mkdocs-material, mkdocs-awesome-pages-plugin, deepspeed\n",
            "Successfully installed backrefs-6.1 bracex-2.6 colorama-0.4.6 deepspeed-0.18.2 ghp-import-2.1.0 hjson-3.1.0 mdx_truly_sane_lists-1.3 mergedeep-1.3.4 mkdocs-1.6.1 mkdocs-awesome-pages-plugin-2.10.1 mkdocs-get-deps-0.2.0 mkdocs-material-9.7.0 mkdocs-material-extensions-1.3.1 multimethod-2.0.2 ninja-1.13.0 paginate-0.5.7 pathspec-0.12.1 pymdown-extensions-10.17.2 pyvista-0.46.4 pyyaml-env-tag-1.1 shortuuid-1.0.13 vtk-9.5.2 wcmatch-10.1\n",
            "âœ… Dependencies Installed. (Skipped setup.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Search for the missing setup.py\n",
        "print(\"Searching for C++ kernel setup.py...\")\n",
        "target_dir = \"/content/PointNeXt/openpoints/cpp\"\n",
        "found_setup = False\n",
        "\n",
        "for root, dirs, files in os.walk(target_dir):\n",
        "    if \"setup.py\" in files:\n",
        "        print(f\"\\u2705 Found setup.py at: {root}\")\n",
        "        found_setup = True\n",
        "\n",
        "        # 2. Force Compile\n",
        "        print(f\"Compiling kernels in {root}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"setup.py\", \"install\"], cwd=root)\n",
        "            print(\"Compilation Successful!\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"\\u274c Compilation Failed: {e}\")\n",
        "\n",
        "if not found_setup:\n",
        "    print(\"\\u274c Critical Error: Could not find setup.py anywhere in openpoints/cpp!\")\n",
        "    print(\"Did the 'git submodule update' step finish successfully?\")"
      ],
      "metadata": {
        "id": "0FjSoHiNPWvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c299818-d845-45c7-aae4-a0517140683b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for C++ kernel setup.py...\n",
            "âœ… Found setup.py at: /content/PointNeXt/openpoints/cpp/pointops\n",
            "Compiling kernels in /content/PointNeXt/openpoints/cpp/pointops...\n",
            "Compilation Successful!\n",
            "âœ… Found setup.py at: /content/PointNeXt/openpoints/cpp/subsampling\n",
            "Compiling kernels in /content/PointNeXt/openpoints/cpp/subsampling...\n",
            "âŒ Compilation Failed: Command '['/usr/bin/python3', 'setup.py', 'install']' returned non-zero exit status 1.\n",
            "âœ… Found setup.py at: /content/PointNeXt/openpoints/cpp/chamfer_dist\n",
            "Compiling kernels in /content/PointNeXt/openpoints/cpp/chamfer_dist...\n",
            "Compilation Successful!\n",
            "âœ… Found setup.py at: /content/PointNeXt/openpoints/cpp/emd\n",
            "Compiling kernels in /content/PointNeXt/openpoints/cpp/emd...\n",
            "Compilation Successful!\n",
            "âœ… Found setup.py at: /content/PointNeXt/openpoints/cpp/pointnet2_batch\n",
            "Compiling kernels in /content/PointNeXt/openpoints/cpp/pointnet2_batch...\n",
            "Compilation Successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Missing Validation List\n",
        "\n",
        "split_dir = \"/content/processed_data/train_test_split\"\n",
        "test_file = os.path.join(split_dir, \"shuffled_test_file_list.json\")\n",
        "val_file = os.path.join(split_dir, \"shuffled_val_file_list.json\")\n",
        "\n",
        "print(\"Checking validation list...\")\n",
        "\n",
        "if os.path.exists(test_file):\n",
        "    if not os.path.exists(val_file):\n",
        "        print(\"Creating dummy validation list (copy of test list)...\")\n",
        "        shutil.copy(test_file, val_file)\n",
        "        print(f\"\\u2705 Created: {val_file}\")\n",
        "    else:\n",
        "        print(\"\\u2705 Validation list already exists.\")\n",
        "else:\n",
        "    print(\"\\u274c Error: Test list not found! Did the previous copy step work?\")"
      ],
      "metadata": {
        "id": "5CMDNVe9o1HH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b20901-7798-48e5-ae6b-fb0300f119e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking validation list...\n",
            "âœ… Validation list already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train On shapenetpart"
      ],
      "metadata": {
        "id": "veAsjknFPqV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch main.py to fix Tensor Key Error\n",
        "import os\n",
        "\n",
        "target_file = \"/content/PointNeXt/examples/shapenetpart/main.py\"\n",
        "print(f\"Patching {target_file} to fix Tensor Key Error...\")\n",
        "\n",
        "with open(target_file, 'r') as f:\n",
        "    code = f.read()\n",
        "\n",
        "# The problematic line: parts = cls2parts[cls[shape_idx]]\n",
        "# We change it to: parts = cls2parts[int(cls[shape_idx])]\n",
        "\n",
        "bad_line = \"parts = cls2parts[cls[shape_idx]]\"\n",
        "good_line = \"parts = cls2parts[int(cls[shape_idx])]\"\n",
        "\n",
        "if bad_line in code:\n",
        "    code = code.replace(bad_line, good_line)\n",
        "    print(\"\\u2705 Patched: Cast tensor to int for dictionary lookup.\")\n",
        "else:\n",
        "    print(\"\\u26A0\\uFE0F Warning: Could not find exact line. Check if file changed.\")\n",
        "\n",
        "with open(target_file, 'w') as f:\n",
        "    f.write(code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNkJ6uQWPwRs",
        "outputId": "61094fbe-07be-4467-9980-c5273ff9229d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patching /content/PointNeXt/examples/shapenetpart/main.py to fix Tensor Key Error...\n",
            "âœ… Patched: Cast tensor to int for dictionary lookup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch shapenetpart/main.py to Fix Scheduler Bug\n",
        "import os\n",
        "\n",
        "target_file = \"/content/PointNeXt/examples/shapenetpart/main.py\"\n",
        "print(f\"Patching scheduler logic in {target_file}...\")\n",
        "\n",
        "with open(target_file, 'r') as f:\n",
        "    code = f.read()\n",
        "\n",
        "# 1. Fix the crash at the end of epoch\n",
        "if \"scheduler.step(epoch)\" in code and \"if scheduler is not None: scheduler.step(epoch)\" not in code:\n",
        "    code = code.replace(\"scheduler.step(epoch)\", \"if scheduler is not None: scheduler.step(epoch)\")\n",
        "    print(\"\\u2705 Patched: Added safety check for scheduler.step()\")\n",
        "\n",
        "# 2. Inject a fallback scheduler if builder fails\n",
        "if \"scheduler = build_scheduler_from_cfg(cfg, optimizer)\" in code and \"if scheduler is None:\" not in code:\n",
        "    fallback_code = \"\"\"scheduler = build_scheduler_from_cfg(cfg, optimizer)\n",
        "    if scheduler is None:\n",
        "        print(\"WARNING: Scheduler failed to build. Using default MultiStepLR.\")\n",
        "        import torch.optim.lr_scheduler as lr_sched\n",
        "        scheduler = lr_sched.MultiStepLR(optimizer, milestones=[70, 90], gamma=0.1)\"\"\"\n",
        "\n",
        "    code = code.replace(\"scheduler = build_scheduler_from_cfg(cfg, optimizer)\", fallback_code)\n",
        "    print(\"\\u2705 Patched: Added fallback scheduler instantiation.\")\n",
        "\n",
        "with open(target_file, 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"\\U0001F680 Ready to Train. Scheduler bug squashed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX1YY3gTQ4FM",
        "outputId": "546222e9-6d7b-4f0b-9e24-654771b5d91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patching scheduler logic in /content/PointNeXt/examples/shapenetpart/main.py...\n",
            "âœ… Patched: Added safety check for scheduler.step()\n",
            "âœ… Patched: Added fallback scheduler instantiation.\n",
            "ğŸš€ Ready to Train. Scheduler bug squashed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW Run Training\n",
        "print(\"\\nStarting Training...\")\n",
        "%cd /content/PointNeXt\n",
        "!PYTHONPATH=. python examples/shapenetpart/main.py --cfg cfgs/shapenetpart/custom_fallen_trees.yaml mode=train"
      ],
      "metadata": {
        "id": "yTC1v-MNyjtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f38ea3d-ee43-4f09-c6a6-4b3a4696ee40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training...\n",
            "/content/PointNeXt\n",
            "2025-12-04 08:31:40.267061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764837100.498362    6159 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764837100.559198    6159 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764837101.022806    6159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764837101.022844    6159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764837101.022849    6159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764837101.022854    6159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-04 08:31:41.068838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/content/PointNeXt/openpoints/models/backbone/pointnetv2.py:79: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  new_features: (B, \\sum_k(mlps[k][-1], npoint)) tensor of the new_features descriptors\n",
            "/content/PointNeXt/openpoints/models/classification/cls_base.py:99: SyntaxWarning: invalid escape sequence '\\e'\n",
            "  $\\eg$ cls_feat='max,avg' means use the concatenateion of maxpooled and avgpooled features.\n",
            "launch mp with 1 GPUs, current rank: 0\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mdist_url: tcp://localhost:8888\n",
            "dist_backend: nccl\n",
            "multiprocessing_distributed: False\n",
            "ngpus_per_node: 1\n",
            "world_size: 1\n",
            "launcher: mp\n",
            "local_rank: 0\n",
            "use_gpu: True\n",
            "seed: 9595\n",
            "epoch: 0\n",
            "epochs: 100\n",
            "ignore_index: None\n",
            "val_fn: validate\n",
            "deterministic: False\n",
            "sync_bn: False\n",
            "criterion_args:\n",
            "  NAME: Poly1FocalLoss\n",
            "use_mask: False\n",
            "grad_norm_clip: 1\n",
            "layer_decay: 0\n",
            "step_per_update: 1\n",
            "start_epoch: 1\n",
            "sched_on_epoch: True\n",
            "wandb:\n",
            "  use_wandb: False\n",
            "  project: PointNext-ShapeNetPart\n",
            "  tags: ['shapenetpart', 'train', 'custom_fallen_trees', 'ngpus1', 'seed9595']\n",
            "  name: shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc\n",
            "use_amp: False\n",
            "use_voting: False\n",
            "val_freq: 1\n",
            "resume: False\n",
            "test: False\n",
            "finetune: False\n",
            "mode: train\n",
            "logname: None\n",
            "load_path: None\n",
            "print_freq: 10\n",
            "save_freq: -1\n",
            "root_dir: log/shapenetpart\n",
            "pretrained_path: None\n",
            "datatransforms:\n",
            "  train: ['PointsToTensor', 'PointCloudScaling', 'PointCloudCenterAndNormalize', 'PointCloudJitter', 'ChromaticDropGPU']\n",
            "  val: ['PointsToTensor', 'PointCloudCenterAndNormalize']\n",
            "  vote: ['PointCloudScaling']\n",
            "  kwargs:\n",
            "    jitter_sigma: 0.001\n",
            "    jitter_clip: 0.005\n",
            "    scale: [0.8, 1.2]\n",
            "    gravity_dim: 1\n",
            "    angle: [0, 1.0, 0]\n",
            "feature_keys: pos,x\n",
            "dataset:\n",
            "  common:\n",
            "    NAME: FallenTreePart\n",
            "    data_root: /content/processed_data\n",
            "    use_normal: False\n",
            "    num_points: 2048\n",
            "    use_xyz: True\n",
            "  train:\n",
            "    split: train\n",
            "  val:\n",
            "    split: val\n",
            "    presample: True\n",
            "num_classes: 4\n",
            "shape_classes: 2\n",
            "num_points: 2048\n",
            "normal_channel: True\n",
            "batch_size: 16\n",
            "dataloader:\n",
            "  num_workers: 4\n",
            "num_votes: 10\n",
            "refine: True\n",
            "lr: 0.001\n",
            "min_lr: None\n",
            "optimizer:\n",
            "  NAME: adamw\n",
            "  weight_decay: 0.0001\n",
            "sched:\n",
            "  NAME: MultiStepLR\n",
            "  milestones: [70, 90]\n",
            "  gamma: 0.1\n",
            "  warmup_epochs: 0\n",
            "decay_epochs: [210, 270]\n",
            "decay_rate: 0.1\n",
            "warmup_epochs: 0\n",
            "model:\n",
            "  NAME: BasePartSeg\n",
            "  encoder_args:\n",
            "    NAME: PointNextEncoder\n",
            "    blocks: [1, 1, 1, 1, 1]\n",
            "    strides: [1, 2, 2, 2, 2]\n",
            "    width: 32\n",
            "    in_channels: 7\n",
            "    sa_layers: 3\n",
            "    sa_use_res: True\n",
            "    radius: 0.1\n",
            "    radius_scaling: 2.5\n",
            "    nsample: 32\n",
            "    expansion: 4\n",
            "    aggr_args:\n",
            "      feature_type: dp_fj\n",
            "    reduction: max\n",
            "    group_args:\n",
            "      NAME: ballquery\n",
            "      normalize_dp: True\n",
            "    conv_args:\n",
            "      order: conv-norm-act\n",
            "    act_args:\n",
            "      act: relu\n",
            "    norm_args:\n",
            "      norm: bn\n",
            "  decoder_args:\n",
            "    NAME: PointNextPartDecoder\n",
            "    cls_map: curvenet\n",
            "  cls_args:\n",
            "    NAME: SegHead\n",
            "    global_feat: max,avg\n",
            "    num_classes: 4\n",
            "    shape_classes: 2\n",
            "    in_channels: None\n",
            "    norm_args:\n",
            "      norm: bn\n",
            "log_dir: log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc\n",
            "rank: 0\n",
            "distributed: False\n",
            "mp: False\n",
            "task_name: shapenetpart\n",
            "cfg_basename: custom_fallen_trees\n",
            "opts: mode=train\n",
            "is_training: True\n",
            "run_name: shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc\n",
            "run_dir: log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc\n",
            "exp_dir: log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc\n",
            "ckpt_dir: log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint\n",
            "log_path: log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc.log\n",
            "cfg_path: log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/cfg.yaml\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mLoading val split from: /content/processed_data/train_test_split/shuffled_val_file_list.json\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mFound 128 valid files for val split.\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mlength of validation dataset: 128\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mnumber of classes of the dataset: 4\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mradius: [[0.1], [0.1], [0.25], [0.625], [1.5625]],\n",
            " nsample: [[32], [32], [32], [32], [32]]\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mNAME: ballquery\n",
            "normalize_dp: True\n",
            "radius: 0.1\n",
            "nsample: 32\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mNAME: ballquery\n",
            "normalize_dp: True\n",
            "radius: 0.25\n",
            "nsample: 32\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mNAME: ballquery\n",
            "normalize_dp: True\n",
            "radius: 0.625\n",
            "nsample: 32\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mNAME: ballquery\n",
            "normalize_dp: True\n",
            "radius: 1.5625\n",
            "nsample: 32\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mkwargs: {'shape_classes': 2} are not used in SegHead\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mBasePartSeg(\n",
            "  (encoder): PointNextEncoder(\n",
            "    (encoder): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): SetAbstraction(\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): SetAbstraction(\n",
            "          (skipconv): Sequential(\n",
            "            (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (act): ReLU(inplace=True)\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv2d(35, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Sequential(\n",
            "              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (grouper): QueryAndGroup()\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): SetAbstraction(\n",
            "          (skipconv): Sequential(\n",
            "            (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (act): ReLU(inplace=True)\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv2d(67, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (grouper): QueryAndGroup()\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): SetAbstraction(\n",
            "          (skipconv): Sequential(\n",
            "            (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (act): ReLU(inplace=True)\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (grouper): QueryAndGroup()\n",
            "        )\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): SetAbstraction(\n",
            "          (skipconv): Sequential(\n",
            "            (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (act): ReLU(inplace=True)\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (grouper): QueryAndGroup()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): PointNextPartDecoder(\n",
            "    (global_conv2): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (global_conv1): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (decoder): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): FeaturePropogation(\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv1d(304, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): FeaturePropogation(\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv1d(192, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): FeaturePropogation(\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv1d(384, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): FeaturePropogation(\n",
            "          (convs): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): Conv1d(768, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "              (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): SegHead(\n",
            "    (head): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv1d(96, 96, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Dropout(p=0.5, inplace=False)\n",
            "      (2): Sequential(\n",
            "        (0): Conv1d(96, 4, kernel_size=(1,), stride=(1,))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mNumber of params: 0.9774 M\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mParam groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.0001,\n",
            "    \"params\": [\n",
            "      \"encoder.encoder.0.0.convs.0.0.weight\",\n",
            "      \"encoder.encoder.1.0.skipconv.0.weight\",\n",
            "      \"encoder.encoder.1.0.convs.0.0.weight\",\n",
            "      \"encoder.encoder.1.0.convs.1.0.weight\",\n",
            "      \"encoder.encoder.1.0.convs.2.0.weight\",\n",
            "      \"encoder.encoder.2.0.skipconv.0.weight\",\n",
            "      \"encoder.encoder.2.0.convs.0.0.weight\",\n",
            "      \"encoder.encoder.2.0.convs.1.0.weight\",\n",
            "      \"encoder.encoder.2.0.convs.2.0.weight\",\n",
            "      \"encoder.encoder.3.0.skipconv.0.weight\",\n",
            "      \"encoder.encoder.3.0.convs.0.0.weight\",\n",
            "      \"encoder.encoder.3.0.convs.1.0.weight\",\n",
            "      \"encoder.encoder.3.0.convs.2.0.weight\",\n",
            "      \"encoder.encoder.4.0.skipconv.0.weight\",\n",
            "      \"encoder.encoder.4.0.convs.0.0.weight\",\n",
            "      \"encoder.encoder.4.0.convs.1.0.weight\",\n",
            "      \"encoder.encoder.4.0.convs.2.0.weight\",\n",
            "      \"decoder.global_conv2.0.0.weight\",\n",
            "      \"decoder.global_conv1.0.0.weight\",\n",
            "      \"decoder.decoder.0.0.convs.0.0.weight\",\n",
            "      \"decoder.decoder.0.0.convs.1.0.weight\",\n",
            "      \"decoder.decoder.1.0.convs.0.0.weight\",\n",
            "      \"decoder.decoder.1.0.convs.1.0.weight\",\n",
            "      \"decoder.decoder.2.0.convs.0.0.weight\",\n",
            "      \"decoder.decoder.2.0.convs.1.0.weight\",\n",
            "      \"decoder.decoder.3.0.convs.0.0.weight\",\n",
            "      \"decoder.decoder.3.0.convs.1.0.weight\",\n",
            "      \"head.head.0.0.weight\",\n",
            "      \"head.head.2.0.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"encoder.encoder.0.0.convs.0.0.bias\",\n",
            "      \"encoder.encoder.1.0.skipconv.0.bias\",\n",
            "      \"encoder.encoder.1.0.convs.0.1.weight\",\n",
            "      \"encoder.encoder.1.0.convs.0.1.bias\",\n",
            "      \"encoder.encoder.1.0.convs.1.1.weight\",\n",
            "      \"encoder.encoder.1.0.convs.1.1.bias\",\n",
            "      \"encoder.encoder.1.0.convs.2.1.weight\",\n",
            "      \"encoder.encoder.1.0.convs.2.1.bias\",\n",
            "      \"encoder.encoder.2.0.skipconv.0.bias\",\n",
            "      \"encoder.encoder.2.0.convs.0.1.weight\",\n",
            "      \"encoder.encoder.2.0.convs.0.1.bias\",\n",
            "      \"encoder.encoder.2.0.convs.1.1.weight\",\n",
            "      \"encoder.encoder.2.0.convs.1.1.bias\",\n",
            "      \"encoder.encoder.2.0.convs.2.1.weight\",\n",
            "      \"encoder.encoder.2.0.convs.2.1.bias\",\n",
            "      \"encoder.encoder.3.0.skipconv.0.bias\",\n",
            "      \"encoder.encoder.3.0.convs.0.1.weight\",\n",
            "      \"encoder.encoder.3.0.convs.0.1.bias\",\n",
            "      \"encoder.encoder.3.0.convs.1.1.weight\",\n",
            "      \"encoder.encoder.3.0.convs.1.1.bias\",\n",
            "      \"encoder.encoder.3.0.convs.2.1.weight\",\n",
            "      \"encoder.encoder.3.0.convs.2.1.bias\",\n",
            "      \"encoder.encoder.4.0.skipconv.0.bias\",\n",
            "      \"encoder.encoder.4.0.convs.0.1.weight\",\n",
            "      \"encoder.encoder.4.0.convs.0.1.bias\",\n",
            "      \"encoder.encoder.4.0.convs.1.1.weight\",\n",
            "      \"encoder.encoder.4.0.convs.1.1.bias\",\n",
            "      \"encoder.encoder.4.0.convs.2.1.weight\",\n",
            "      \"encoder.encoder.4.0.convs.2.1.bias\",\n",
            "      \"decoder.global_conv2.0.0.bias\",\n",
            "      \"decoder.global_conv1.0.0.bias\",\n",
            "      \"decoder.decoder.0.0.convs.0.1.weight\",\n",
            "      \"decoder.decoder.0.0.convs.0.1.bias\",\n",
            "      \"decoder.decoder.0.0.convs.1.1.weight\",\n",
            "      \"decoder.decoder.0.0.convs.1.1.bias\",\n",
            "      \"decoder.decoder.1.0.convs.0.1.weight\",\n",
            "      \"decoder.decoder.1.0.convs.0.1.bias\",\n",
            "      \"decoder.decoder.1.0.convs.1.1.weight\",\n",
            "      \"decoder.decoder.1.0.convs.1.1.bias\",\n",
            "      \"decoder.decoder.2.0.convs.0.1.weight\",\n",
            "      \"decoder.decoder.2.0.convs.0.1.bias\",\n",
            "      \"decoder.decoder.2.0.convs.1.1.weight\",\n",
            "      \"decoder.decoder.2.0.convs.1.1.bias\",\n",
            "      \"decoder.decoder.3.0.convs.0.1.weight\",\n",
            "      \"decoder.decoder.3.0.convs.0.1.bias\",\n",
            "      \"decoder.decoder.3.0.convs.1.1.weight\",\n",
            "      \"decoder.decoder.3.0.convs.1.1.bias\",\n",
            "      \"head.head.0.1.weight\",\n",
            "      \"head.head.0.1.bias\",\n",
            "      \"head.head.2.0.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "WARNING: Scheduler failed to build. Using default MultiStepLR.\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mTraining from scratch\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mLoading train split from: /content/processed_data/train_test_split/shuffled_train_file_list.json\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mFound 721 valid files for train split.\n",
            "\u001b[32m[12/04 08:31:55 FallenTreePart]: \u001b[0mlength of training dataset: 721\n",
            "Train Epoch [1/100] Loss 0.112 : 100% 45/45 [00:16<00:00,  2.78it/s]\n",
            "100% 8/8 [00:01<00:00,  7.80it/s]\n",
            "\u001b[32m[12/04 08:32:12 FallenTreePart]: \u001b[0mTest Epoch [1/100],Instance mIoU 86.38, Class mIoU 84.97, \n",
            " Class mIoUs tensor([100.0000,  69.9435], device='cuda:0')\n",
            "\u001b[32m[12/04 08:32:12 FallenTreePart]: \u001b[0mFind a better ckpt @E1, val_ins_miou 86.38 val_cls_miou 84.97, \n",
            "cls_mious: tensor([100.0000,  69.9435], device='cuda:0')\n",
            "\u001b[32m[12/04 08:32:12 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [2/100] Loss 0.039 : 100% 45/45 [00:07<00:00,  6.01it/s]\n",
            "100% 8/8 [00:00<00:00, 10.61it/s]\n",
            "\u001b[32m[12/04 08:32:21 FallenTreePart]: \u001b[0mTest Epoch [2/100],Instance mIoU 84.71, Class mIoU 83.57, \n",
            " Class mIoUs tensor([95.7143, 71.4280], device='cuda:0')\n",
            "Train Epoch [3/100] Loss 0.029 : 100% 45/45 [00:07<00:00,  5.98it/s]\n",
            "100% 8/8 [00:00<00:00, 11.37it/s]\n",
            "\u001b[32m[12/04 08:32:29 FallenTreePart]: \u001b[0mTest Epoch [3/100],Instance mIoU 88.77, Class mIoU 87.75, \n",
            " Class mIoUs tensor([98.5714, 76.9340], device='cuda:0')\n",
            "\u001b[32m[12/04 08:32:29 FallenTreePart]: \u001b[0mFind a better ckpt @E3, val_ins_miou 88.77 val_cls_miou 87.75, \n",
            "cls_mious: tensor([98.5714, 76.9340], device='cuda:0')\n",
            "\u001b[32m[12/04 08:32:30 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [4/100] Loss 0.022 : 100% 45/45 [00:07<00:00,  5.97it/s]\n",
            "100% 8/8 [00:00<00:00,  8.65it/s]\n",
            "\u001b[32m[12/04 08:32:38 FallenTreePart]: \u001b[0mTest Epoch [4/100],Instance mIoU 88.05, Class mIoU 86.82, \n",
            " Class mIoUs tensor([100.0000,  73.6357], device='cuda:0')\n",
            "Train Epoch [5/100] Loss 0.019 : 100% 45/45 [00:07<00:00,  5.97it/s]\n",
            "100% 8/8 [00:00<00:00, 10.87it/s]\n",
            "\u001b[32m[12/04 08:32:47 FallenTreePart]: \u001b[0mTest Epoch [5/100],Instance mIoU 88.94, Class mIoU 87.80, \n",
            " Class mIoUs tensor([100.0000,  75.6019], device='cuda:0')\n",
            "\u001b[32m[12/04 08:32:47 FallenTreePart]: \u001b[0mFind a better ckpt @E5, val_ins_miou 88.94 val_cls_miou 87.80, \n",
            "cls_mious: tensor([100.0000,  75.6019], device='cuda:0')\n",
            "\u001b[32m[12/04 08:32:47 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [6/100] Loss 0.016 : 100% 45/45 [00:07<00:00,  5.87it/s]\n",
            "100% 8/8 [00:00<00:00, 10.95it/s]\n",
            "\u001b[32m[12/04 08:32:56 FallenTreePart]: \u001b[0mTest Epoch [6/100],Instance mIoU 88.69, Class mIoU 87.66, \n",
            " Class mIoUs tensor([98.5714, 76.7537], device='cuda:0')\n",
            "Train Epoch [7/100] Loss 0.017 : 100% 45/45 [00:07<00:00,  5.81it/s]\n",
            "100% 8/8 [00:00<00:00,  8.86it/s]\n",
            "\u001b[32m[12/04 08:33:05 FallenTreePart]: \u001b[0mTest Epoch [7/100],Instance mIoU 88.40, Class mIoU 87.34, \n",
            " Class mIoUs tensor([98.5714, 76.1166], device='cuda:0')\n",
            "Train Epoch [8/100] Loss 0.015 : 100% 45/45 [00:07<00:00,  5.82it/s]\n",
            "100% 8/8 [00:00<00:00, 11.17it/s]\n",
            "\u001b[32m[12/04 08:33:14 FallenTreePart]: \u001b[0mTest Epoch [8/100],Instance mIoU 90.16, Class mIoU 89.14, \n",
            " Class mIoUs tensor([100.0000,  78.2733], device='cuda:0')\n",
            "\u001b[32m[12/04 08:33:14 FallenTreePart]: \u001b[0mFind a better ckpt @E8, val_ins_miou 90.16 val_cls_miou 89.14, \n",
            "cls_mious: tensor([100.0000,  78.2733], device='cuda:0')\n",
            "\u001b[32m[12/04 08:33:14 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [9/100] Loss 0.014 : 100% 45/45 [00:07<00:00,  5.77it/s]\n",
            "100% 8/8 [00:00<00:00, 10.65it/s]\n",
            "\u001b[32m[12/04 08:33:22 FallenTreePart]: \u001b[0mTest Epoch [9/100],Instance mIoU 90.07, Class mIoU 89.04, \n",
            " Class mIoUs tensor([100.0000,  78.0795], device='cuda:0')\n",
            "Train Epoch [10/100] Loss 0.015 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00,  9.18it/s]\n",
            "\u001b[32m[12/04 08:33:32 FallenTreePart]: \u001b[0mTest Epoch [10/100],Instance mIoU 89.26, Class mIoU 88.29, \n",
            " Class mIoUs tensor([98.5714, 78.0132], device='cuda:0')\n",
            "Train Epoch [11/100] Loss 0.020 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00,  9.71it/s]\n",
            "\u001b[32m[12/04 08:33:41 FallenTreePart]: \u001b[0mTest Epoch [11/100],Instance mIoU 89.02, Class mIoU 87.89, \n",
            " Class mIoUs tensor([100.0000,  75.7761], device='cuda:0')\n",
            "Train Epoch [12/100] Loss 0.016 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00, 10.89it/s]\n",
            "\u001b[32m[12/04 08:33:50 FallenTreePart]: \u001b[0mTest Epoch [12/100],Instance mIoU 86.54, Class mIoU 85.30, \n",
            " Class mIoUs tensor([98.5714, 72.0295], device='cuda:0')\n",
            "Train Epoch [13/100] Loss 0.013 : 100% 45/45 [00:08<00:00,  5.61it/s]\n",
            "100% 8/8 [00:00<00:00,  9.61it/s]\n",
            "\u001b[32m[12/04 08:33:59 FallenTreePart]: \u001b[0mTest Epoch [13/100],Instance mIoU 85.91, Class mIoU 84.61, \n",
            " Class mIoUs tensor([98.5714, 70.6398], device='cuda:0')\n",
            "Train Epoch [14/100] Loss 0.013 : 100% 45/45 [00:07<00:00,  5.67it/s]\n",
            "100% 8/8 [00:00<00:00, 10.52it/s]\n",
            "\u001b[32m[12/04 08:34:08 FallenTreePart]: \u001b[0mTest Epoch [14/100],Instance mIoU 88.30, Class mIoU 87.24, \n",
            " Class mIoUs tensor([98.5714, 75.9000], device='cuda:0')\n",
            "Train Epoch [15/100] Loss 0.009 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.17it/s]\n",
            "\u001b[32m[12/04 08:34:17 FallenTreePart]: \u001b[0mTest Epoch [15/100],Instance mIoU 92.69, Class mIoU 92.08, \n",
            " Class mIoUs tensor([98.5714, 85.5951], device='cuda:0')\n",
            "\u001b[32m[12/04 08:34:17 FallenTreePart]: \u001b[0mFind a better ckpt @E15, val_ins_miou 92.69 val_cls_miou 92.08, \n",
            "cls_mious: tensor([98.5714, 85.5951], device='cuda:0')\n",
            "\u001b[32m[12/04 08:34:17 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [16/100] Loss 0.007 : 100% 45/45 [00:07<00:00,  5.63it/s]\n",
            "100% 8/8 [00:00<00:00, 10.48it/s]\n",
            "\u001b[32m[12/04 08:34:26 FallenTreePart]: \u001b[0mTest Epoch [16/100],Instance mIoU 92.05, Class mIoU 91.38, \n",
            " Class mIoUs tensor([98.5714, 84.1862], device='cuda:0')\n",
            "Train Epoch [17/100] Loss 0.006 : 100% 45/45 [00:07<00:00,  5.72it/s]\n",
            "100% 8/8 [00:00<00:00, 10.25it/s]\n",
            "\u001b[32m[12/04 08:34:35 FallenTreePart]: \u001b[0mTest Epoch [17/100],Instance mIoU 93.88, Class mIoU 93.25, \n",
            " Class mIoUs tensor([100.0000,  86.4942], device='cuda:0')\n",
            "\u001b[32m[12/04 08:34:35 FallenTreePart]: \u001b[0mFind a better ckpt @E17, val_ins_miou 93.88 val_cls_miou 93.25, \n",
            "cls_mious: tensor([100.0000,  86.4942], device='cuda:0')\n",
            "\u001b[32m[12/04 08:34:35 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [18/100] Loss 0.006 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00, 10.77it/s]\n",
            "\u001b[32m[12/04 08:34:44 FallenTreePart]: \u001b[0mTest Epoch [18/100],Instance mIoU 92.46, Class mIoU 91.68, \n",
            " Class mIoUs tensor([100.0000,  83.3675], device='cuda:0')\n",
            "Train Epoch [19/100] Loss 0.006 : 100% 45/45 [00:07<00:00,  5.73it/s]\n",
            "100% 8/8 [00:00<00:00, 10.43it/s]\n",
            "\u001b[32m[12/04 08:34:53 FallenTreePart]: \u001b[0mTest Epoch [19/100],Instance mIoU 89.39, Class mIoU 88.29, \n",
            " Class mIoUs tensor([100.0000,  76.5785], device='cuda:0')\n",
            "Train Epoch [20/100] Loss 0.006 : 100% 45/45 [00:07<00:00,  5.73it/s]\n",
            "100% 8/8 [00:00<00:00, 10.92it/s]\n",
            "\u001b[32m[12/04 08:35:02 FallenTreePart]: \u001b[0mTest Epoch [20/100],Instance mIoU 93.81, Class mIoU 93.17, \n",
            " Class mIoUs tensor([100.0000,  86.3325], device='cuda:0')\n",
            "Train Epoch [21/100] Loss 0.005 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 11.19it/s]\n",
            "\u001b[32m[12/04 08:35:11 FallenTreePart]: \u001b[0mTest Epoch [21/100],Instance mIoU 92.78, Class mIoU 92.03, \n",
            " Class mIoUs tensor([100.0000,  84.0572], device='cuda:0')\n",
            "Train Epoch [22/100] Loss 0.005 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 11.01it/s]\n",
            "\u001b[32m[12/04 08:35:20 FallenTreePart]: \u001b[0mTest Epoch [22/100],Instance mIoU 92.16, Class mIoU 91.35, \n",
            " Class mIoUs tensor([100.0000,  82.6972], device='cuda:0')\n",
            "Train Epoch [23/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00,  9.18it/s]\n",
            "\u001b[32m[12/04 08:35:29 FallenTreePart]: \u001b[0mTest Epoch [23/100],Instance mIoU 92.16, Class mIoU 91.35, \n",
            " Class mIoUs tensor([100.0000,  82.6928], device='cuda:0')\n",
            "Train Epoch [24/100] Loss 0.004 : 100% 45/45 [00:08<00:00,  5.62it/s]\n",
            "100% 8/8 [00:00<00:00, 10.32it/s]\n",
            "\u001b[32m[12/04 08:35:38 FallenTreePart]: \u001b[0mTest Epoch [24/100],Instance mIoU 92.71, Class mIoU 91.96, \n",
            " Class mIoUs tensor([100.0000,  83.9115], device='cuda:0')\n",
            "Train Epoch [25/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.85it/s]\n",
            "\u001b[32m[12/04 08:35:47 FallenTreePart]: \u001b[0mTest Epoch [25/100],Instance mIoU 91.20, Class mIoU 90.29, \n",
            " Class mIoUs tensor([100.0000,  80.5718], device='cuda:0')\n",
            "Train Epoch [26/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00,  8.49it/s]\n",
            "\u001b[32m[12/04 08:35:57 FallenTreePart]: \u001b[0mTest Epoch [26/100],Instance mIoU 92.60, Class mIoU 91.84, \n",
            " Class mIoUs tensor([100.0000,  83.6774], device='cuda:0')\n",
            "Train Epoch [27/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00, 10.85it/s]\n",
            "\u001b[32m[12/04 08:36:06 FallenTreePart]: \u001b[0mTest Epoch [27/100],Instance mIoU 93.15, Class mIoU 92.44, \n",
            " Class mIoUs tensor([100.0000,  84.8877], device='cuda:0')\n",
            "Train Epoch [28/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.92it/s]\n",
            "\u001b[32m[12/04 08:36:15 FallenTreePart]: \u001b[0mTest Epoch [28/100],Instance mIoU 93.59, Class mIoU 92.93, \n",
            " Class mIoUs tensor([100.0000,  85.8553], device='cuda:0')\n",
            "Train Epoch [29/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00,  8.92it/s]\n",
            "\u001b[32m[12/04 08:36:24 FallenTreePart]: \u001b[0mTest Epoch [29/100],Instance mIoU 91.77, Class mIoU 91.06, \n",
            " Class mIoUs tensor([98.5714, 83.5550], device='cuda:0')\n",
            "Train Epoch [30/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 10.32it/s]\n",
            "\u001b[32m[12/04 08:36:33 FallenTreePart]: \u001b[0mTest Epoch [30/100],Instance mIoU 93.17, Class mIoU 92.46, \n",
            " Class mIoUs tensor([100.0000,  84.9256], device='cuda:0')\n",
            "Train Epoch [31/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.66it/s]\n",
            "\u001b[32m[12/04 08:36:42 FallenTreePart]: \u001b[0mTest Epoch [31/100],Instance mIoU 94.11, Class mIoU 93.50, \n",
            " Class mIoUs tensor([100.0000,  87.0050], device='cuda:0')\n",
            "\u001b[32m[12/04 08:36:42 FallenTreePart]: \u001b[0mFind a better ckpt @E31, val_ins_miou 94.11 val_cls_miou 93.50, \n",
            "cls_mious: tensor([100.0000,  87.0050], device='cuda:0')\n",
            "\u001b[32m[12/04 08:36:42 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [32/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00,  8.52it/s]\n",
            "\u001b[32m[12/04 08:36:51 FallenTreePart]: \u001b[0mTest Epoch [32/100],Instance mIoU 94.54, Class mIoU 93.98, \n",
            " Class mIoUs tensor([100.0000,  87.9504], device='cuda:0')\n",
            "\u001b[32m[12/04 08:36:51 FallenTreePart]: \u001b[0mFind a better ckpt @E32, val_ins_miou 94.54 val_cls_miou 93.98, \n",
            "cls_mious: tensor([100.0000,  87.9504], device='cuda:0')\n",
            "\u001b[32m[12/04 08:36:51 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [33/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 10.89it/s]\n",
            "\u001b[32m[12/04 08:37:00 FallenTreePart]: \u001b[0mTest Epoch [33/100],Instance mIoU 93.84, Class mIoU 93.20, \n",
            " Class mIoUs tensor([100.0000,  86.4100], device='cuda:0')\n",
            "Train Epoch [34/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 11.21it/s]\n",
            "\u001b[32m[12/04 08:37:09 FallenTreePart]: \u001b[0mTest Epoch [34/100],Instance mIoU 94.61, Class mIoU 94.05, \n",
            " Class mIoUs tensor([100.0000,  88.1099], device='cuda:0')\n",
            "\u001b[32m[12/04 08:37:09 FallenTreePart]: \u001b[0mFind a better ckpt @E34, val_ins_miou 94.61 val_cls_miou 94.05, \n",
            "cls_mious: tensor([100.0000,  88.1099], device='cuda:0')\n",
            "\u001b[32m[12/04 08:37:09 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [35/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.63it/s]\n",
            "100% 8/8 [00:00<00:00,  9.31it/s]\n",
            "\u001b[32m[12/04 08:37:19 FallenTreePart]: \u001b[0mTest Epoch [35/100],Instance mIoU 93.43, Class mIoU 92.75, \n",
            " Class mIoUs tensor([100.0000,  85.5016], device='cuda:0')\n",
            "Train Epoch [36/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.52it/s]\n",
            "\u001b[32m[12/04 08:37:28 FallenTreePart]: \u001b[0mTest Epoch [36/100],Instance mIoU 94.47, Class mIoU 93.90, \n",
            " Class mIoUs tensor([100.0000,  87.7918], device='cuda:0')\n",
            "Train Epoch [37/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.63it/s]\n",
            "\u001b[32m[12/04 08:37:36 FallenTreePart]: \u001b[0mTest Epoch [37/100],Instance mIoU 95.16, Class mIoU 94.66, \n",
            " Class mIoUs tensor([100.0000,  89.3262], device='cuda:0')\n",
            "\u001b[32m[12/04 08:37:36 FallenTreePart]: \u001b[0mFind a better ckpt @E37, val_ins_miou 95.16 val_cls_miou 94.66, \n",
            "cls_mious: tensor([100.0000,  89.3262], device='cuda:0')\n",
            "\u001b[32m[12/04 08:37:37 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [38/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.64it/s]\n",
            "100% 8/8 [00:00<00:00,  9.98it/s]\n",
            "\u001b[32m[12/04 08:37:46 FallenTreePart]: \u001b[0mTest Epoch [38/100],Instance mIoU 94.63, Class mIoU 94.08, \n",
            " Class mIoUs tensor([100.0000,  88.1533], device='cuda:0')\n",
            "Train Epoch [39/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.67it/s]\n",
            "100% 8/8 [00:00<00:00, 10.97it/s]\n",
            "\u001b[32m[12/04 08:37:55 FallenTreePart]: \u001b[0mTest Epoch [39/100],Instance mIoU 94.13, Class mIoU 93.53, \n",
            " Class mIoUs tensor([100.0000,  87.0520], device='cuda:0')\n",
            "Train Epoch [40/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00, 10.48it/s]\n",
            "\u001b[32m[12/04 08:38:04 FallenTreePart]: \u001b[0mTest Epoch [40/100],Instance mIoU 93.97, Class mIoU 93.35, \n",
            " Class mIoUs tensor([100.0000,  86.7000], device='cuda:0')\n",
            "Train Epoch [41/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.69it/s]\n",
            "\u001b[32m[12/04 08:38:13 FallenTreePart]: \u001b[0mTest Epoch [41/100],Instance mIoU 94.22, Class mIoU 93.63, \n",
            " Class mIoUs tensor([100.0000,  87.2514], device='cuda:0')\n",
            "Train Epoch [42/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.26it/s]\n",
            "\u001b[32m[12/04 08:38:22 FallenTreePart]: \u001b[0mTest Epoch [42/100],Instance mIoU 94.18, Class mIoU 93.57, \n",
            " Class mIoUs tensor([100.0000,  87.1496], device='cuda:0')\n",
            "Train Epoch [43/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.64it/s]\n",
            "100% 8/8 [00:00<00:00, 10.51it/s]\n",
            "\u001b[32m[12/04 08:38:31 FallenTreePart]: \u001b[0mTest Epoch [43/100],Instance mIoU 93.15, Class mIoU 92.44, \n",
            " Class mIoUs tensor([100.0000,  84.8757], device='cuda:0')\n",
            "Train Epoch [44/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 10.50it/s]\n",
            "\u001b[32m[12/04 08:38:40 FallenTreePart]: \u001b[0mTest Epoch [44/100],Instance mIoU 93.84, Class mIoU 93.21, \n",
            " Class mIoUs tensor([100.0000,  86.4104], device='cuda:0')\n",
            "Train Epoch [45/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00,  8.89it/s]\n",
            "\u001b[32m[12/04 08:38:49 FallenTreePart]: \u001b[0mTest Epoch [45/100],Instance mIoU 93.84, Class mIoU 93.20, \n",
            " Class mIoUs tensor([100.0000,  86.3969], device='cuda:0')\n",
            "Train Epoch [46/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 10.47it/s]\n",
            "\u001b[32m[12/04 08:38:58 FallenTreePart]: \u001b[0mTest Epoch [46/100],Instance mIoU 93.65, Class mIoU 92.99, \n",
            " Class mIoUs tensor([100.0000,  85.9845], device='cuda:0')\n",
            "Train Epoch [47/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.63it/s]\n",
            "\u001b[32m[12/04 08:39:07 FallenTreePart]: \u001b[0mTest Epoch [47/100],Instance mIoU 94.67, Class mIoU 94.12, \n",
            " Class mIoUs tensor([100.0000,  88.2436], device='cuda:0')\n",
            "Train Epoch [48/100] Loss 0.017 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00,  8.82it/s]\n",
            "\u001b[32m[12/04 08:39:16 FallenTreePart]: \u001b[0mTest Epoch [48/100],Instance mIoU 79.58, Class mIoU 77.46, \n",
            " Class mIoUs tensor([100.0000,  54.9276], device='cuda:0')\n",
            "Train Epoch [49/100] Loss 0.026 : 100% 45/45 [00:08<00:00,  5.55it/s]\n",
            "100% 8/8 [00:00<00:00, 10.41it/s]\n",
            "\u001b[32m[12/04 08:39:25 FallenTreePart]: \u001b[0mTest Epoch [49/100],Instance mIoU 77.74, Class mIoU 75.46, \n",
            " Class mIoUs tensor([99.7015, 51.2276], device='cuda:0')\n",
            "Train Epoch [50/100] Loss 0.017 : 100% 45/45 [00:07<00:00,  5.72it/s]\n",
            "100% 8/8 [00:00<00:00, 10.64it/s]\n",
            "\u001b[32m[12/04 08:39:34 FallenTreePart]: \u001b[0mTest Epoch [50/100],Instance mIoU 92.73, Class mIoU 91.98, \n",
            " Class mIoUs tensor([100.0000,  83.9560], device='cuda:0')\n",
            "Train Epoch [51/100] Loss 0.012 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00,  8.16it/s]\n",
            "\u001b[32m[12/04 08:39:44 FallenTreePart]: \u001b[0mTest Epoch [51/100],Instance mIoU 89.37, Class mIoU 89.01, \n",
            " Class mIoUs tensor([92.8571, 85.1641], device='cuda:0')\n",
            "Train Epoch [52/100] Loss 0.009 : 100% 45/45 [00:07<00:00,  5.64it/s]\n",
            "100% 8/8 [00:00<00:00, 10.90it/s]\n",
            "\u001b[32m[12/04 08:39:53 FallenTreePart]: \u001b[0mTest Epoch [52/100],Instance mIoU 91.95, Class mIoU 91.12, \n",
            " Class mIoUs tensor([100.0000,  82.2439], device='cuda:0')\n",
            "Train Epoch [53/100] Loss 0.007 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 11.10it/s]\n",
            "\u001b[32m[12/04 08:40:02 FallenTreePart]: \u001b[0mTest Epoch [53/100],Instance mIoU 95.49, Class mIoU 95.03, \n",
            " Class mIoUs tensor([100.0000,  90.0518], device='cuda:0')\n",
            "\u001b[32m[12/04 08:40:02 FallenTreePart]: \u001b[0mFind a better ckpt @E53, val_ins_miou 95.49 val_cls_miou 95.03, \n",
            "cls_mious: tensor([100.0000,  90.0518], device='cuda:0')\n",
            "\u001b[32m[12/04 08:40:02 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [54/100] Loss 0.006 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00,  8.83it/s]\n",
            "\u001b[32m[12/04 08:40:11 FallenTreePart]: \u001b[0mTest Epoch [54/100],Instance mIoU 93.48, Class mIoU 92.81, \n",
            " Class mIoUs tensor([100.0000,  85.6151], device='cuda:0')\n",
            "Train Epoch [55/100] Loss 0.005 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00, 11.25it/s]\n",
            "\u001b[32m[12/04 08:40:20 FallenTreePart]: \u001b[0mTest Epoch [55/100],Instance mIoU 94.61, Class mIoU 94.05, \n",
            " Class mIoUs tensor([100.0000,  88.0974], device='cuda:0')\n",
            "Train Epoch [56/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 11.03it/s]\n",
            "\u001b[32m[12/04 08:40:29 FallenTreePart]: \u001b[0mTest Epoch [56/100],Instance mIoU 94.69, Class mIoU 94.14, \n",
            " Class mIoUs tensor([100.0000,  88.2855], device='cuda:0')\n",
            "Train Epoch [57/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.63it/s]\n",
            "100% 8/8 [00:00<00:00,  8.54it/s]\n",
            "\u001b[32m[12/04 08:40:38 FallenTreePart]: \u001b[0mTest Epoch [57/100],Instance mIoU 94.31, Class mIoU 93.72, \n",
            " Class mIoUs tensor([100.0000,  87.4415], device='cuda:0')\n",
            "Train Epoch [58/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.81it/s]\n",
            "\u001b[32m[12/04 08:40:47 FallenTreePart]: \u001b[0mTest Epoch [58/100],Instance mIoU 94.03, Class mIoU 93.41, \n",
            " Class mIoUs tensor([100.0000,  86.8221], device='cuda:0')\n",
            "Train Epoch [59/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.92it/s]\n",
            "\u001b[32m[12/04 08:40:56 FallenTreePart]: \u001b[0mTest Epoch [59/100],Instance mIoU 92.99, Class mIoU 92.26, \n",
            " Class mIoUs tensor([100.0000,  84.5275], device='cuda:0')\n",
            "Train Epoch [60/100] Loss 0.004 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00,  9.50it/s]\n",
            "\u001b[32m[12/04 08:41:05 FallenTreePart]: \u001b[0mTest Epoch [60/100],Instance mIoU 94.21, Class mIoU 93.61, \n",
            " Class mIoUs tensor([100.0000,  87.2246], device='cuda:0')\n",
            "Train Epoch [61/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.45it/s]\n",
            "\u001b[32m[12/04 08:41:14 FallenTreePart]: \u001b[0mTest Epoch [61/100],Instance mIoU 95.32, Class mIoU 94.84, \n",
            " Class mIoUs tensor([100.0000,  89.6791], device='cuda:0')\n",
            "Train Epoch [62/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 11.13it/s]\n",
            "\u001b[32m[12/04 08:41:23 FallenTreePart]: \u001b[0mTest Epoch [62/100],Instance mIoU 95.16, Class mIoU 94.65, \n",
            " Class mIoUs tensor([100.0000,  89.3082], device='cuda:0')\n",
            "Train Epoch [63/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00,  9.57it/s]\n",
            "\u001b[32m[12/04 08:41:33 FallenTreePart]: \u001b[0mTest Epoch [63/100],Instance mIoU 95.64, Class mIoU 95.19, \n",
            " Class mIoUs tensor([100.0000,  90.3806], device='cuda:0')\n",
            "\u001b[32m[12/04 08:41:33 FallenTreePart]: \u001b[0mFind a better ckpt @E63, val_ins_miou 95.64 val_cls_miou 95.19, \n",
            "cls_mious: tensor([100.0000,  90.3806], device='cuda:0')\n",
            "\u001b[32m[12/04 08:41:33 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [64/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.73it/s]\n",
            "100% 8/8 [00:00<00:00, 10.58it/s]\n",
            "\u001b[32m[12/04 08:41:41 FallenTreePart]: \u001b[0mTest Epoch [64/100],Instance mIoU 95.81, Class mIoU 95.38, \n",
            " Class mIoUs tensor([100.0000,  90.7600], device='cuda:0')\n",
            "\u001b[32m[12/04 08:41:41 FallenTreePart]: \u001b[0mFind a better ckpt @E64, val_ins_miou 95.81 val_cls_miou 95.38, \n",
            "cls_mious: tensor([100.0000,  90.7600], device='cuda:0')\n",
            "\u001b[32m[12/04 08:41:42 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [65/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.66it/s]\n",
            "\u001b[32m[12/04 08:41:50 FallenTreePart]: \u001b[0mTest Epoch [65/100],Instance mIoU 96.00, Class mIoU 95.58, \n",
            " Class mIoUs tensor([100.0000,  91.1622], device='cuda:0')\n",
            "\u001b[32m[12/04 08:41:50 FallenTreePart]: \u001b[0mFind a better ckpt @E65, val_ins_miou 96.00 val_cls_miou 95.58, \n",
            "cls_mious: tensor([100.0000,  91.1622], device='cuda:0')\n",
            "\u001b[32m[12/04 08:41:51 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [66/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 10.85it/s]\n",
            "\u001b[32m[12/04 08:41:59 FallenTreePart]: \u001b[0mTest Epoch [66/100],Instance mIoU 95.59, Class mIoU 95.13, \n",
            " Class mIoUs tensor([100.0000,  90.2665], device='cuda:0')\n",
            "Train Epoch [67/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.72it/s]\n",
            "100% 8/8 [00:00<00:00, 10.60it/s]\n",
            "\u001b[32m[12/04 08:42:08 FallenTreePart]: \u001b[0mTest Epoch [67/100],Instance mIoU 95.93, Class mIoU 95.51, \n",
            " Class mIoUs tensor([100.0000,  91.0161], device='cuda:0')\n",
            "Train Epoch [68/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.67it/s]\n",
            "100% 8/8 [00:00<00:00, 10.46it/s]\n",
            "\u001b[32m[12/04 08:42:17 FallenTreePart]: \u001b[0mTest Epoch [68/100],Instance mIoU 95.68, Class mIoU 95.23, \n",
            " Class mIoUs tensor([100.0000,  90.4566], device='cuda:0')\n",
            "Train Epoch [69/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 10.60it/s]\n",
            "\u001b[32m[12/04 08:42:26 FallenTreePart]: \u001b[0mTest Epoch [69/100],Instance mIoU 95.45, Class mIoU 94.98, \n",
            " Class mIoUs tensor([100.0000,  89.9617], device='cuda:0')\n",
            "Train Epoch [70/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.73it/s]\n",
            "100% 8/8 [00:00<00:00,  9.84it/s]\n",
            "\u001b[32m[12/04 08:42:35 FallenTreePart]: \u001b[0mTest Epoch [70/100],Instance mIoU 94.55, Class mIoU 93.99, \n",
            " Class mIoUs tensor([100.0000,  87.9820], device='cuda:0')\n",
            "Train Epoch [71/100] Loss 0.003 : 100% 45/45 [00:07<00:00,  5.63it/s]\n",
            "100% 8/8 [00:00<00:00, 10.63it/s]\n",
            "\u001b[32m[12/04 08:42:45 FallenTreePart]: \u001b[0mTest Epoch [71/100],Instance mIoU 95.91, Class mIoU 95.49, \n",
            " Class mIoUs tensor([100.0000,  90.9750], device='cuda:0')\n",
            "Train Epoch [72/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.77it/s]\n",
            "\u001b[32m[12/04 08:42:53 FallenTreePart]: \u001b[0mTest Epoch [72/100],Instance mIoU 96.02, Class mIoU 95.60, \n",
            " Class mIoUs tensor([100.0000,  91.2075], device='cuda:0')\n",
            "\u001b[32m[12/04 08:42:53 FallenTreePart]: \u001b[0mFind a better ckpt @E72, val_ins_miou 96.02 val_cls_miou 95.60, \n",
            "cls_mious: tensor([100.0000,  91.2075], device='cuda:0')\n",
            "\u001b[32m[12/04 08:42:54 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [73/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00,  9.28it/s]\n",
            "\u001b[32m[12/04 08:43:03 FallenTreePart]: \u001b[0mTest Epoch [73/100],Instance mIoU 96.04, Class mIoU 95.63, \n",
            " Class mIoUs tensor([100.0000,  91.2689], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:03 FallenTreePart]: \u001b[0mFind a better ckpt @E73, val_ins_miou 96.04 val_cls_miou 95.63, \n",
            "cls_mious: tensor([100.0000,  91.2689], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:03 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [74/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.67it/s]\n",
            "100% 8/8 [00:00<00:00, 10.98it/s]\n",
            "\u001b[32m[12/04 08:43:12 FallenTreePart]: \u001b[0mTest Epoch [74/100],Instance mIoU 96.08, Class mIoU 95.67, \n",
            " Class mIoUs tensor([100.0000,  91.3384], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:12 FallenTreePart]: \u001b[0mFind a better ckpt @E74, val_ins_miou 96.08 val_cls_miou 95.67, \n",
            "cls_mious: tensor([100.0000,  91.3384], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:12 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [75/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.54it/s]\n",
            "\u001b[32m[12/04 08:43:21 FallenTreePart]: \u001b[0mTest Epoch [75/100],Instance mIoU 96.09, Class mIoU 95.68, \n",
            " Class mIoUs tensor([100.0000,  91.3620], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:21 FallenTreePart]: \u001b[0mFind a better ckpt @E75, val_ins_miou 96.09 val_cls_miou 95.68, \n",
            "cls_mious: tensor([100.0000,  91.3620], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:21 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [76/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00,  8.51it/s]\n",
            "\u001b[32m[12/04 08:43:30 FallenTreePart]: \u001b[0mTest Epoch [76/100],Instance mIoU 96.10, Class mIoU 95.70, \n",
            " Class mIoUs tensor([100.0000,  91.3938], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:30 FallenTreePart]: \u001b[0mFind a better ckpt @E76, val_ins_miou 96.10 val_cls_miou 95.70, \n",
            "cls_mious: tensor([100.0000,  91.3938], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:30 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [77/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 10.79it/s]\n",
            "\u001b[32m[12/04 08:43:39 FallenTreePart]: \u001b[0mTest Epoch [77/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4146], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:39 FallenTreePart]: \u001b[0mFind a better ckpt @E77, val_ins_miou 96.11 val_cls_miou 95.71, \n",
            "cls_mious: tensor([100.0000,  91.4146], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:39 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [78/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.20it/s]\n",
            "\u001b[32m[12/04 08:43:48 FallenTreePart]: \u001b[0mTest Epoch [78/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4141], device='cuda:0')\n",
            "Train Epoch [79/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00,  8.85it/s]\n",
            "\u001b[32m[12/04 08:43:57 FallenTreePart]: \u001b[0mTest Epoch [79/100],Instance mIoU 96.12, Class mIoU 95.72, \n",
            " Class mIoUs tensor([100.0000,  91.4324], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:57 FallenTreePart]: \u001b[0mFind a better ckpt @E79, val_ins_miou 96.12 val_cls_miou 95.72, \n",
            "cls_mious: tensor([100.0000,  91.4324], device='cuda:0')\n",
            "\u001b[32m[12/04 08:43:57 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [80/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 10.55it/s]\n",
            "\u001b[32m[12/04 08:44:06 FallenTreePart]: \u001b[0mTest Epoch [80/100],Instance mIoU 96.12, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4288], device='cuda:0')\n",
            "Train Epoch [81/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.75it/s]\n",
            "\u001b[32m[12/04 08:44:15 FallenTreePart]: \u001b[0mTest Epoch [81/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4214], device='cuda:0')\n",
            "Train Epoch [82/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.67it/s]\n",
            "100% 8/8 [00:00<00:00,  8.76it/s]\n",
            "\u001b[32m[12/04 08:44:25 FallenTreePart]: \u001b[0mTest Epoch [82/100],Instance mIoU 96.12, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4276], device='cuda:0')\n",
            "Train Epoch [83/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.66it/s]\n",
            "100% 8/8 [00:00<00:00, 10.83it/s]\n",
            "\u001b[32m[12/04 08:44:34 FallenTreePart]: \u001b[0mTest Epoch [83/100],Instance mIoU 96.12, Class mIoU 95.72, \n",
            " Class mIoUs tensor([100.0000,  91.4369], device='cuda:0')\n",
            "\u001b[32m[12/04 08:44:34 FallenTreePart]: \u001b[0mFind a better ckpt @E83, val_ins_miou 96.12 val_cls_miou 95.72, \n",
            "cls_mious: tensor([100.0000,  91.4369], device='cuda:0')\n",
            "\u001b[32m[12/04 08:44:34 FallenTreePart]: \u001b[0mFound the best model and saved in log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "Train Epoch [84/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00, 10.62it/s]\n",
            "\u001b[32m[12/04 08:44:43 FallenTreePart]: \u001b[0mTest Epoch [84/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4249], device='cuda:0')\n",
            "Train Epoch [85/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00,  9.10it/s]\n",
            "\u001b[32m[12/04 08:44:52 FallenTreePart]: \u001b[0mTest Epoch [85/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4152], device='cuda:0')\n",
            "Train Epoch [86/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.72it/s]\n",
            "100% 8/8 [00:00<00:00, 10.74it/s]\n",
            "\u001b[32m[12/04 08:45:01 FallenTreePart]: \u001b[0mTest Epoch [86/100],Instance mIoU 96.10, Class mIoU 95.70, \n",
            " Class mIoUs tensor([100.0000,  91.3999], device='cuda:0')\n",
            "Train Epoch [87/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.72it/s]\n",
            "100% 8/8 [00:00<00:00, 11.15it/s]\n",
            "\u001b[32m[12/04 08:45:10 FallenTreePart]: \u001b[0mTest Epoch [87/100],Instance mIoU 96.10, Class mIoU 95.69, \n",
            " Class mIoUs tensor([100.0000,  91.3870], device='cuda:0')\n",
            "Train Epoch [88/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.72it/s]\n",
            "100% 8/8 [00:00<00:00,  9.61it/s]\n",
            "\u001b[32m[12/04 08:45:19 FallenTreePart]: \u001b[0mTest Epoch [88/100],Instance mIoU 96.09, Class mIoU 95.69, \n",
            " Class mIoUs tensor([100.0000,  91.3760], device='cuda:0')\n",
            "Train Epoch [89/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.74it/s]\n",
            "100% 8/8 [00:00<00:00, 10.62it/s]\n",
            "\u001b[32m[12/04 08:45:28 FallenTreePart]: \u001b[0mTest Epoch [89/100],Instance mIoU 96.09, Class mIoU 95.68, \n",
            " Class mIoUs tensor([100.0000,  91.3617], device='cuda:0')\n",
            "Train Epoch [90/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.84it/s]\n",
            "\u001b[32m[12/04 08:45:37 FallenTreePart]: \u001b[0mTest Epoch [90/100],Instance mIoU 96.08, Class mIoU 95.68, \n",
            " Class mIoUs tensor([100.0000,  91.3531], device='cuda:0')\n",
            "Train Epoch [91/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00,  9.96it/s]\n",
            "\u001b[32m[12/04 08:45:46 FallenTreePart]: \u001b[0mTest Epoch [91/100],Instance mIoU 96.10, Class mIoU 95.70, \n",
            " Class mIoUs tensor([100.0000,  91.4031], device='cuda:0')\n",
            "Train Epoch [92/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00, 10.53it/s]\n",
            "\u001b[32m[12/04 08:45:55 FallenTreePart]: \u001b[0mTest Epoch [92/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4185], device='cuda:0')\n",
            "Train Epoch [93/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.70it/s]\n",
            "100% 8/8 [00:00<00:00, 10.67it/s]\n",
            "\u001b[32m[12/04 08:46:04 FallenTreePart]: \u001b[0mTest Epoch [93/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4206], device='cuda:0')\n",
            "Train Epoch [94/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.68it/s]\n",
            "100% 8/8 [00:00<00:00, 10.64it/s]\n",
            "\u001b[32m[12/04 08:46:12 FallenTreePart]: \u001b[0mTest Epoch [94/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4204], device='cuda:0')\n",
            "Train Epoch [95/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00, 10.52it/s]\n",
            "\u001b[32m[12/04 08:46:21 FallenTreePart]: \u001b[0mTest Epoch [95/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4228], device='cuda:0')\n",
            "Train Epoch [96/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 11.11it/s]\n",
            "\u001b[32m[12/04 08:46:30 FallenTreePart]: \u001b[0mTest Epoch [96/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4218], device='cuda:0')\n",
            "Train Epoch [97/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.69it/s]\n",
            "100% 8/8 [00:00<00:00, 10.74it/s]\n",
            "\u001b[32m[12/04 08:46:39 FallenTreePart]: \u001b[0mTest Epoch [97/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4172], device='cuda:0')\n",
            "Train Epoch [98/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00,  9.83it/s]\n",
            "\u001b[32m[12/04 08:46:48 FallenTreePart]: \u001b[0mTest Epoch [98/100],Instance mIoU 96.11, Class mIoU 95.71, \n",
            " Class mIoUs tensor([100.0000,  91.4158], device='cuda:0')\n",
            "Train Epoch [99/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.65it/s]\n",
            "100% 8/8 [00:00<00:00, 10.76it/s]\n",
            "\u001b[32m[12/04 08:46:58 FallenTreePart]: \u001b[0mTest Epoch [99/100],Instance mIoU 96.11, Class mIoU 95.70, \n",
            " Class mIoUs tensor([100.0000,  91.4094], device='cuda:0')\n",
            "Train Epoch [100/100] Loss 0.002 : 100% 45/45 [00:07<00:00,  5.71it/s]\n",
            "100% 8/8 [00:00<00:00, 11.03it/s]\n",
            "\u001b[32m[12/04 08:47:06 FallenTreePart]: \u001b[0mTest Epoch [100/100],Instance mIoU 96.11, Class mIoU 95.70, \n",
            " Class mIoUs tensor([100.0000,  91.4090], device='cuda:0')\n",
            "\u001b[32m[12/04 08:47:07 FallenTreePart]: \u001b[0mBest Epoch 83,Instance mIoU 96.12, Class mIoU 95.72, \n",
            " Class mIoUs tensor([100.0000,  91.4369], device='cuda:0')\n",
            "\u001b[32m[12/04 08:47:07 FallenTreePart]: \u001b[0mSuccessful Loading the ckpt from log/shapenetpart/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc/checkpoint/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n",
            "\u001b[32m[12/04 08:47:07 FallenTreePart]: \u001b[0mckpts @ 83 epoch( {} )\n",
            "100% 8/8 [00:05<00:00,  1.45it/s]\n",
            "\u001b[32m[12/04 08:47:12 FallenTreePart]: \u001b[0mTest Epoch [100/100],Instance mIoU 96.33, Class mIoU 95.95, \n",
            " Class mIoUs tensor([100.0000,  91.9014], device='cuda:0')\n",
            "\u001b[32m[12/04 08:47:12 FallenTreePart]: \u001b[0m---Voting---\n",
            "Best Epoch 83,Voting Instance mIoU 96.33, Voting Class mIoU 95.95, \n",
            " Voting Class mIoUs tensor([100.0000,  91.9014], device='cuda:0')\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/PointNeXt/examples/shapenetpart/main.py\", line 451, in <module>\n",
            "    main(0, cfg)\n",
            "  File \"/content/PointNeXt/examples/shapenetpart/main.py\", line 287, in main\n",
            "    dist.destroy_process_group()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py\", line 1721, in destroy_process_group\n",
            "    assert pg is not None\n",
            "           ^^^^^^^^^^^^^^\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save to Drive"
      ],
      "metadata": {
        "id": "WiZVTd19mU_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smart Backup using Glob\n",
        "import glob\n",
        "\n",
        "# 1. Define the pattern (The * acts as the regex)\n",
        "# We look for any folder starting with the project name inside the log dir\n",
        "search_pattern = \"/content/PointNeXt/log/shapenetpart/shapenetpart-train-custom_fallen_trees*\"\n",
        "\n",
        "print(f\" Searching for runs matching: {search_pattern}...\")\n",
        "\n",
        "# 2. Find all matching folders\n",
        "found_folders = glob.glob(search_pattern)\n",
        "\n",
        "if not found_folders:\n",
        "    print(\"\\u274c Error: No training folders found matching that pattern.\")\n",
        "else:\n",
        "    # 3. Pick the LATEST folder (in case trained multiple times)\n",
        "    latest_run_dir = max(found_folders, key=os.path.getmtime)\n",
        "    print(f\"\\u2705 Found latest run: {os.path.basename(latest_run_dir)}\")\n",
        "\n",
        "    # 4. Construct the checkpoint path\n",
        "    source_ckpt_dir = os.path.join(latest_run_dir, \"checkpoint\")\n",
        "    drive_model_dir = \"/content/drive/MyDrive/ML_Projects/PointNeXt/Models\"\n",
        "\n",
        "    # 5. Perform Backup\n",
        "    if os.path.exists(source_ckpt_dir):\n",
        "        os.makedirs(drive_model_dir, exist_ok=True)\n",
        "        files = glob.glob(os.path.join(source_ckpt_dir, \"*_best.pth\"))\n",
        "\n",
        "        if files:\n",
        "            best_model = files[0]\n",
        "            filename = os.path.basename(best_model)\n",
        "            dest_path = os.path.join(drive_model_dir, filename)\n",
        "            shutil.copy(best_model, dest_path)\n",
        "            print(f\"\\U0001F4BE Success! Model saved to: {dest_path}\")\n",
        "        else:\n",
        "            print(\"\\u26A0\\uFE0F Warning: No '_best.pth' file found.\")\n",
        "    else:\n",
        "        print(f\"\\u274c Error: Checkpoint folder missing in {latest_run_dir}\")"
      ],
      "metadata": {
        "id": "1tfOQoTPqBcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b7a874-d00f-4cc4-b331-f038d2a19720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Searching for runs matching: /content/PointNeXt/log/shapenetpart/shapenetpart-train-custom_fallen_trees*...\n",
            "âœ… Found latest run: shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc\n",
            "ğŸ’¾ Success! Model saved to: /content/drive/MyDrive/ML_Projects/PointNeXt/Models/shapenetpart-train-custom_fallen_trees-ngpus1-seed9595-20251204-083155-kgvdwTsWewBrpjtnGFjphc_ckpt_best.pth\n"
          ]
        }
      ]
    }
  ]
}